{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project mainly contains 3 relational datasets with text and non-text features. The data process is described in process_data.py. \n",
    "\n",
    "Briefly speaking, we merge 3 datasets by their primary keys, randomly sample 20% from the merged datasets. We then scale numeric features to have zero mean and unit variance, create dummy variables for categorical features, and extract TF-IDF then apply LSA for text features. When everything is ready, the processed data is split into training set and testing set.\n",
    "\n",
    "The purpose of machine learning is to learn the underlying function in training set and generalize the algorithm to testing set. Although there are different measures for the performance of this generalization, in the following context we adopt precision and recall as our measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import get_processed_data\n",
    "features_processed_all, labels = get_processed_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features_processed_all, labels, test_size=0.2, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We employ majority voting classifier in this project, which is comprised of many weak learners: logistic regression, random forest, dicision tree, support vector machine, and nearest neighbors. Before we feed data into weak classifiers, a dimension reduction tool (principal component analysis) is performed to filter noise in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "clf1 = LogisticRegression(class_weight='balanced')\n",
    "clf2 = RandomForestClassifier(n_estimators=200, random_state=1111)\n",
    "clf3 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=1111)\n",
    "clf4 = SVC(kernel='poly')\n",
    "clf5 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "\n",
    "pipe1 = Pipeline([ ['pca', pca], ['lr', clf1] ])\n",
    "pipe2 = Pipeline([ ['pca', pca], ['rf', clf2] ])\n",
    "pipe3 = Pipeline([ ['pca', pca], ['tree', clf3] ])\n",
    "pipe4 = Pipeline([ ['pca', pca], ['svm', clf4] ])\n",
    "pipe5 = Pipeline([ ['pca', pca], ['knn', clf5] ])\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "mv_clf = VotingClassifier(estimators=[('lr', pipe1), ('rf', pipe2), ('tree', pipe3), ('svm', pipe4), ('knn', pipe5)], voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first present our base model. The result shows that the precision is about 89% and recall is about 69%. What does this mean? \n",
    "\n",
    "Precision aims to answer the question: what proportion of positive \"predictions\" was actually correct?\n",
    "\n",
    "Recall aims to answer the question: What proportion of \"real\" positives was predicted correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mv_clf.fit(X_train, Y_train)\n",
    "Y_predicted_mv = mv_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7102   72]\n",
      " [ 254  573]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(Y_test, Y_predicted_mv)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      7174\n",
      "          1       0.89      0.69      0.78       827\n",
      "\n",
      "avg / total       0.96      0.96      0.96      8001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, Y_predicted_mv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV can be used to find best parameters, as illustrated below. If we use pipeline in the procedure, it may not be easy to find parameters in GridSearchCV. Fortunately, the .get_params().keys() method is useful to figure out what those parameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check parameters by: mv_clf.get_params().keys()\n",
    "params = {'lr__lr__C': [0.5, 1.0, 1.5], 'rf__rf__n_estimators': [200, 300, 400], 'svm__svm__kernel': ['rbf', 'poly']}\n",
    "grid = GridSearchCV(estimator=mv_clf, param_grid=params, cv=5)\n",
    "grid = grid.fit(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'lr__lr__C': 1.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.953 (+/-0.011) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.013) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.010) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.011) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.010) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.009) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.010) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.013) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.011) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.012) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.010) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "0.944 (+/-0.010) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.011) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.012) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.010) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.012) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.009) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.009) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'poly'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
