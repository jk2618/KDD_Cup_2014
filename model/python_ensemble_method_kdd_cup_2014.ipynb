{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project is complex enough to capture many concepts: (1) it is a relational dataset; (2) it contains text and non-text features; (3) its labels is imbalanced, i.e. only 10% of the labels are exciting (successful). \n",
    "\n",
    "The data process is described in process_data.py. \n",
    "\n",
    "Briefly speaking, we merge 3 datasets by their primary keys, randomly sample 20% from the merged datasets. We then scale numeric features to have zero mean and unit variance, create dummy variables for categorical features, and extract TF-IDF then apply LSA for text features. When everything is ready, the processed data is split into training set and testing set.\n",
    "\n",
    "The purpose of machine learning is to learn the underlying function in training set and generalize the algorithm to testing set. Although are many ways to evaluate the performance of machine learning models, in this context we use cross validation, which is suitable for medium-sized dataset, to select the best model. Finally, we will look at precision instead of accuracy due to the imbalance of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import get_processed_data\n",
    "features_processed_all, labels = get_processed_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features_processed_all, labels, test_size=0.2, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Voting Classifier\n",
    "\n",
    "A majority voting classifier in employed, which is comprised of many base learners: logistic regression, random forest, dicision tree, support vector machine, and K nearest neighbors. Before we feed the data into base classifiers, a dimension reduction tool (principal component analysis) is applied to reduce the noise in the features.\n",
    "\n",
    "First presented is our base estimator. Afterwards, we utilize GridSearchCV for tuning model parameters. Since there are 5 classifiers, it is a daunting task to exhaust all possible parameter combinations. In the following we only demonstrate the concept of model (parameter) tuning via GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "clf1 = LogisticRegression(class_weight='balanced', C=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=200, random_state=1111)\n",
    "clf3 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=1111)\n",
    "clf4 = SVC(kernel='poly')\n",
    "clf5 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "\n",
    "pipe1 = Pipeline([ ['pca', pca], ['lr', clf1] ])\n",
    "pipe2 = Pipeline([ ['pca', pca], ['rf', clf2] ])\n",
    "pipe3 = Pipeline([ ['pca', pca], ['tree', clf3] ])\n",
    "pipe4 = Pipeline([ ['pca', pca], ['svm', clf4] ])\n",
    "pipe5 = Pipeline([ ['pca', pca], ['knn', clf5] ])\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "mv_clf = VotingClassifier(estimators=[('lr', pipe1), ('rf', pipe2), ('tree', pipe3), ('svm', pipe4), ('knn', pipe5)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf.fit(X_train, Y_train)\n",
    "Y_predicted_mv = mv_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall\n",
    "\n",
    "The result shows that the precision is about 89% and recall is about 69%. What does this mean? \n",
    "\n",
    "Precision aims to answer the question: what proportion of positive \"predictions\" was actually correct?\n",
    "\n",
    "Recall aims to answer the question: What proportion of \"real\" positives was predicted correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7102   72]\n",
      " [ 255  572]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(Y_test, Y_predicted_mv)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      7174\n",
      "          1       0.89      0.69      0.78       827\n",
      "\n",
      "avg / total       0.96      0.96      0.96      8001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, Y_predicted_mv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning\n",
    "\n",
    "What if we are not satisfied with the base estimator and intend to try other parameters?\n",
    "\n",
    "GridSearchCV can be used to find best parameters, as illustrated below. If we use pipeline in the procedure, it may not be easy to find parameters in GridSearchCV. Fortunately, the .get_params().keys() method is useful to figure out what those parameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check parameters by: mv_clf.get_params().keys()\n",
    "params = {'lr__lr__C': [0.5, 1.0, 1.5], 'rf__rf__n_estimators': [200, 300, 400], 'svm__svm__kernel': ['rbf', 'poly']}\n",
    "grid = GridSearchCV(estimator=mv_clf, param_grid=params, cv=5)\n",
    "grid = grid.fit(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'lr__lr__C': 0.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.953 (+/-0.010) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.013) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.010) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.011) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.010) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.009) for {'lr__lr__C': 0.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.011) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'rbf'}\n",
      "0.944 (+/-0.013) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.010) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.011) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.009) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "0.944 (+/-0.009) for {'lr__lr__C': 1.0, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.010) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.012) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 200, 'svm__svm__kernel': 'poly'}\n",
      "0.953 (+/-0.009) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'rbf'}\n",
      "0.943 (+/-0.012) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 300, 'svm__svm__kernel': 'poly'}\n",
      "0.954 (+/-0.009) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'rbf'}\n",
      "0.944 (+/-0.010) for {'lr__lr__C': 1.5, 'rf__rf__n_estimators': 400, 'svm__svm__kernel': 'poly'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the best parameters is C = 0.5 in logistic regression, n_estimators = 400 in random forest, and svm_kernel = 'rbf in support vector machine as suggested by cross validation score, it is worth trying these parameters and see what will happen to the precision and the recall.\n",
    "\n",
    "The result shows that the precision decreases 1% but recall increases 9%, hence eventually we have 88% precision and 79% recall. The improvement could be made by considering: (1) proceed with more refined feature engineering; (2) favor \"soft\" voting rule because not every classifier possesses the same certainty; (3) exhaust all possible combinations of parameters in GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "clf1_2 = LogisticRegression(class_weight='balanced', C=0.5)\n",
    "clf2_2 = RandomForestClassifier(n_estimators=400, random_state=1111)\n",
    "clf3_2 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=1111)\n",
    "clf4_2 = SVC(kernel='rbf')\n",
    "clf5_2 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "\n",
    "pipe1_2 = Pipeline([ ['pca', pca], ['lr', clf1_2] ])\n",
    "pipe2_2 = Pipeline([ ['pca', pca], ['rf', clf2_2] ])\n",
    "pipe3_2 = Pipeline([ ['pca', pca], ['tree', clf3_2] ])\n",
    "pipe4_2 = Pipeline([ ['pca', pca], ['svm', clf4_2] ])\n",
    "pipe5_2 = Pipeline([ ['pca', pca], ['knn', clf5_2] ])\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "mv_clf2 = VotingClassifier(estimators=[('lr', pipe1_2), ('rf', pipe2_2), ('tree', pipe3_2), ('svm', pipe4_2), ('knn', pipe5_2)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf2.fit(X_train, Y_train)\n",
    "Y_predicted_mv2 = mv_clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7089   85]\n",
      " [ 176  651]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix2 = confusion_matrix(Y_test, Y_predicted_mv2)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      7174\n",
      "          1       0.88      0.79      0.83       827\n",
      "\n",
      "avg / total       0.97      0.97      0.97      8001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, Y_predicted_mv2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other measurements coming soon..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
